#!/usr/bin/env python3
"""
ç³»çµ±ç›£æ§æ•¸æ“šå­˜å„²æ¨¡å¡Š
ä½¿ç”¨ SQLite å­˜å„²æ™‚åºæ•¸æ“š
"""

import sqlite3
import json
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import threading


class MonitoringDatabase:
    """ç›£æ§æ•¸æ“šåº«ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "monitoring.db"):
        """
        åˆå§‹åŒ–æ•¸æ“šåº«
        
        Args:
            db_path: è³‡æ–™åº«æª”æ¡ˆè·¯å¾‘
        """
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # è³‡æ–™åº«é€£æ¥é–
        self._lock = threading.Lock()
        
        # åˆå§‹åŒ–è³‡æ–™åº«çµæ§‹
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–è³‡æ–™åº«çµæ§‹"""
        with self._get_connection() as conn:
            cursor = conn.cursor()
            
            # å‰µå»ºä¸»è¦æ•¸æ“šè¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS system_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    unix_timestamp REAL NOT NULL,
                    cpu_usage REAL,
                    ram_usage REAL,
                    ram_used_gb REAL,
                    ram_total_gb REAL,
                    gpu_usage REAL,
                    vram_usage REAL,
                    vram_used_mb REAL,
                    vram_total_mb REAL,
                    gpu_temperature REAL,
                    raw_data TEXT
                )
            """)
            
            # å‰µå»º GPU é€²ç¨‹æ•¸æ“šè¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS gpu_processes (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    unix_timestamp REAL NOT NULL,
                    pid INTEGER NOT NULL,
                    process_name TEXT,
                    command TEXT,
                    gpu_uuid TEXT,
                    gpu_memory_mb REAL,
                    cpu_percent REAL,
                    ram_mb REAL,
                    start_time TEXT,
                    raw_data TEXT
                )
            """)
            
            # å‰µå»ºç´¢å¼•æé«˜æŸ¥è©¢æ•ˆèƒ½
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_timestamp 
                ON system_metrics(unix_timestamp)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_datetime 
                ON system_metrics(timestamp)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_gpu_proc_timestamp 
                ON gpu_processes(unix_timestamp)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_gpu_proc_pid 
                ON gpu_processes(pid, unix_timestamp)
            """)
            
            # å‰µå»ºé…ç½®è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS config (
                    key TEXT PRIMARY KEY,
                    value TEXT,
                    updated_at TEXT
                )
            """)
            
            conn.commit()
    
    def _get_connection(self) -> sqlite3.Connection:
        """ç²å–è³‡æ–™åº«é€£æ¥"""
        conn = sqlite3.connect(self.db_path, timeout=30.0)
        conn.row_factory = sqlite3.Row  # å…è¨±é€šéåˆ—åè¨ªå•
        return conn
    
    def insert_metrics(self, data: Dict) -> bool:
        """
        æ’å…¥ç›£æ§æ•¸æ“š
        
        Args:
            data: ç›£æ§æ•¸æ“šå­—å…¸
            
        Returns:
            æ˜¯å¦æ’å…¥æˆåŠŸ
        """
        try:
            with self._lock:
                with self._get_connection() as conn:
                    cursor = conn.cursor()
                    
                    cursor.execute("""
                        INSERT INTO system_metrics (
                            timestamp, unix_timestamp, cpu_usage, ram_usage, 
                            ram_used_gb, ram_total_gb, gpu_usage, vram_usage,
                            vram_used_mb, vram_total_mb, gpu_temperature, raw_data
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        data.get('timestamp'),
                        data.get('unix_timestamp'),
                        data.get('cpu_usage'),
                        data.get('ram_usage'),
                        data.get('ram_used_gb'),
                        data.get('ram_total_gb'),
                        data.get('gpu_usage'),
                        data.get('vram_usage'),
                        data.get('vram_used_mb'),
                        data.get('vram_total_mb'),
                        data.get('gpu_temperature'),
                        json.dumps(data)  # ä¿å­˜å®Œæ•´åŸå§‹æ•¸æ“š
                    ))
                    
                    conn.commit()
                    return True
                    
        except Exception as e:
            print(f"âŒ æ’å…¥æ•¸æ“šå¤±æ•—: {e}")
            return False
    
    def get_metrics(self, 
                   start_time: Optional[datetime] = None,
                   end_time: Optional[datetime] = None,
                   limit: Optional[int] = None) -> List[Dict]:
        """
        æŸ¥è©¢ç›£æ§æ•¸æ“š
        
        Args:
            start_time: é–‹å§‹æ™‚é–“
            end_time: çµæŸæ™‚é–“
            limit: é™åˆ¶è¿”å›æ•¸é‡
            
        Returns:
            ç›£æ§æ•¸æ“šåˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
                conditions = []
                params = []
                
                if start_time:
                    conditions.append("unix_timestamp >= ?")
                    params.append(start_time.timestamp())
                
                if end_time:
                    conditions.append("unix_timestamp <= ?")
                    params.append(end_time.timestamp())
                
                where_clause = ""
                if conditions:
                    where_clause = "WHERE " + " AND ".join(conditions)
                
                order_clause = "ORDER BY unix_timestamp DESC"
                limit_clause = ""
                if limit:
                    limit_clause = f"LIMIT {limit}"
                
                query = f"""
                    SELECT * FROM system_metrics 
                    {where_clause} 
                    {order_clause} 
                    {limit_clause}
                """
                
                cursor.execute(query, params)
                rows = cursor.fetchall()
                
                # è½‰æ›ç‚ºå­—å…¸åˆ—è¡¨
                metrics = []
                for row in rows:
                    metric = dict(row)
                    # è§£æåŸå§‹æ•¸æ“š
                    if metric.get('raw_data'):
                        try:
                            metric['raw_data'] = json.loads(metric['raw_data'])
                        except json.JSONDecodeError:
                            pass
                    metrics.append(metric)
                
                return metrics
                
        except Exception as e:
            print(f"âŒ æŸ¥è©¢æ•¸æ“šå¤±æ•—: {e}")
            return []
    
    def get_latest_metrics(self, count: int = 1) -> List[Dict]:
        """ç²å–æœ€æ–°çš„ç›£æ§æ•¸æ“š"""
        return self.get_metrics(limit=count)
    
    def insert_gpu_processes(self, processes: List[Dict], timestamp: Optional[datetime] = None) -> bool:
        """
        æ’å…¥ GPU é€²ç¨‹æ•¸æ“š
        
        Args:
            processes: é€²ç¨‹ä¿¡æ¯åˆ—è¡¨
            timestamp: æ™‚é–“æˆ³ï¼ˆå¯é¸ï¼Œé è¨­ä½¿ç”¨ç•¶å‰æ™‚é–“ï¼‰
            
        Returns:
            æ˜¯å¦æ’å…¥æˆåŠŸ
        """
        if not processes:
            return True
            
        if timestamp is None:
            timestamp = datetime.now()
            
        try:
            with self._lock:
                with self._get_connection() as conn:
                    cursor = conn.cursor()
                    
                    # æ‰¹é‡æ’å…¥é€²ç¨‹æ•¸æ“š
                    for process in processes:
                        cursor.execute("""
                            INSERT INTO gpu_processes (
                                timestamp, unix_timestamp, pid, process_name, command,
                                gpu_uuid, gpu_memory_mb, cpu_percent, ram_mb, start_time, raw_data
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            timestamp.isoformat(),
                            timestamp.timestamp(),
                            process.get('pid'),
                            process.get('name'),
                            process.get('command'),
                            process.get('gpu_uuid'),
                            process.get('gpu_memory_mb'),
                            process.get('cpu_percent'),
                            process.get('ram_mb'),
                            process.get('start_time'),
                            json.dumps(process)
                        ))
                    
                    conn.commit()
                    return True
                    
        except Exception as e:
            print(f"âŒ æ’å…¥ GPU é€²ç¨‹æ•¸æ“šå¤±æ•—: {e}")
            return False
    
    def get_gpu_processes(self, 
                         start_time: Optional[datetime] = None,
                         end_time: Optional[datetime] = None,
                         pid: Optional[int] = None,
                         limit: Optional[int] = None) -> List[Dict]:
        """
        æŸ¥è©¢ GPU é€²ç¨‹æ•¸æ“š
        
        Args:
            start_time: é–‹å§‹æ™‚é–“
            end_time: çµæŸæ™‚é–“
            pid: ç‰¹å®šé€²ç¨‹ ID
            limit: é™åˆ¶è¿”å›æ•¸é‡
            
        Returns:
            é€²ç¨‹æ•¸æ“šåˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
                conditions = []
                params = []
                
                if start_time:
                    conditions.append("unix_timestamp >= ?")
                    params.append(start_time.timestamp())
                
                if end_time:
                    conditions.append("unix_timestamp <= ?")
                    params.append(end_time.timestamp())
                
                if pid:
                    conditions.append("pid = ?")
                    params.append(pid)
                
                where_clause = ""
                if conditions:
                    where_clause = "WHERE " + " AND ".join(conditions)
                
                order_clause = "ORDER BY unix_timestamp DESC"
                limit_clause = ""
                if limit:
                    limit_clause = f"LIMIT {limit}"
                
                query = f"""
                    SELECT * FROM gpu_processes 
                    {where_clause} 
                    {order_clause} 
                    {limit_clause}
                """
                
                cursor.execute(query, params)
                rows = cursor.fetchall()
                
                # è½‰æ›ç‚ºå­—å…¸åˆ—è¡¨
                processes = []
                for row in rows:
                    process = dict(row)
                    # è§£æåŸå§‹æ•¸æ“š
                    if process.get('raw_data'):
                        try:
                            process['raw_data'] = json.loads(process['raw_data'])
                        except json.JSONDecodeError:
                            pass
                    processes.append(process)
                
                return processes
                
        except Exception as e:
            print(f"âŒ æŸ¥è©¢ GPU é€²ç¨‹æ•¸æ“šå¤±æ•—: {e}")
            return []
    
    def get_top_gpu_processes_by_timespan(self, timespan: str = '1h', limit: int = 10) -> List[Dict]:
        """
        æ ¹æ“šæ™‚é–“ç¯„åœç²å–æ¶ˆè€— GPU æœ€å¤šçš„é€²ç¨‹
        
        Args:
            timespan: æ™‚é–“ç¯„åœ ('1h', '6h', '24h', '7d')
            limit: è¿”å›æ•¸é‡é™åˆ¶
            
        Returns:
            é€²ç¨‹ä¿¡æ¯åˆ—è¡¨ï¼ŒæŒ‰ GPU è¨˜æ†¶é«”ä½¿ç”¨é‡æ’åº
        """
        now = datetime.now()
        
        # è§£ææ™‚é–“ç¯„åœ
        if timespan.endswith('h'):
            hours = int(timespan[:-1])
            start_time = now - timedelta(hours=hours)
        elif timespan.endswith('d'):
            days = int(timespan[:-1])
            start_time = now - timedelta(days=days)
        else:
            # é è¨­ 1 å°æ™‚
            start_time = now - timedelta(hours=1)
        
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # æŸ¥è©¢æŒ‡å®šæ™‚é–“ç¯„åœå…§å¹³å‡ GPU è¨˜æ†¶é«”ä½¿ç”¨é‡æœ€é«˜çš„é€²ç¨‹
                query = """
                    SELECT 
                        pid,
                        process_name,
                        command,
                        AVG(gpu_memory_mb) as avg_gpu_memory,
                        MAX(gpu_memory_mb) as max_gpu_memory,
                        COUNT(*) as sample_count,
                        MAX(timestamp) as last_seen
                    FROM gpu_processes 
                    WHERE unix_timestamp >= ? 
                    GROUP BY pid, process_name 
                    ORDER BY avg_gpu_memory DESC 
                    LIMIT ?
                """
                
                cursor.execute(query, (start_time.timestamp(), limit))
                rows = cursor.fetchall()
                
                return [dict(row) for row in rows]
                
        except Exception as e:
            print(f"âŒ æŸ¥è©¢é ‚ç´š GPU é€²ç¨‹å¤±æ•—: {e}")
            return []
    
    def get_metrics_by_timespan(self, timespan: str) -> List[Dict]:
        """
        æ ¹æ“šæ™‚é–“ç¯„åœç²å–æ•¸æ“š
        
        Args:
            timespan: æ™‚é–“ç¯„åœ (æ”¯æ´: '90m', '24h', '3000s', '7d' ç­‰æ ¼å¼)
        """
        import re
        
        now = datetime.now()
        
        # è§£ææ™‚é–“ç¯„åœ - æ”¯æ´æ›´å¤šæ ¼å¼
        if timespan.endswith('s'):
            # ç§’ï¼š3000s
            seconds = int(timespan[:-1])
            start_time = now - timedelta(seconds=seconds)
        elif timespan.endswith('m'):
            # åˆ†é˜ï¼š90m
            minutes = int(timespan[:-1])
            start_time = now - timedelta(minutes=minutes)
        elif timespan.endswith('h'):
            # å°æ™‚ï¼š24h
            hours = int(timespan[:-1])
            start_time = now - timedelta(hours=hours)
        elif timespan.endswith('d'):
            # å¤©ï¼š7d
            days = int(timespan[:-1])
            start_time = now - timedelta(days=days)
        elif timespan.endswith('w'):
            # é€±ï¼š2w
            weeks = int(timespan[:-1])
            start_time = now - timedelta(weeks=weeks)
        else:
            # é è¨­ 24 å°æ™‚
            start_time = now - timedelta(hours=24)
        
        return self.get_metrics(start_time=start_time, end_time=now)
    
    def cleanup_old_data(self, keep_days: int = 30) -> int:
        """
        æ¸…ç†èˆŠæ•¸æ“š
        
        Args:
            keep_days: ä¿ç•™å¤©æ•¸
            
        Returns:
            åˆªé™¤çš„è¨˜éŒ„æ•¸
        """
        try:
            cutoff_time = datetime.now() - timedelta(days=keep_days)
            
            with self._lock:
                with self._get_connection() as conn:
                    cursor = conn.cursor()
                    
                    cursor.execute("""
                        DELETE FROM system_metrics 
                        WHERE unix_timestamp < ?
                    """, (cutoff_time.timestamp(),))
                    
                    deleted_count = cursor.rowcount
                    conn.commit()
                    
                    # å„ªåŒ–è³‡æ–™åº«
                    cursor.execute("VACUUM")
                    
                    return deleted_count
                    
        except Exception as e:
            print(f"âŒ æ¸…ç†æ•¸æ“šå¤±æ•—: {e}")
            return 0
    
    def get_statistics(self) -> Dict:
        """ç²å–è³‡æ–™åº«çµ±è¨ˆè³‡è¨Š"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # ç¸½è¨˜éŒ„æ•¸
                cursor.execute("SELECT COUNT(*) FROM system_metrics")
                total_records = cursor.fetchone()[0]
                
                # æ™‚é–“ç¯„åœ
                cursor.execute("""
                    SELECT MIN(unix_timestamp), MAX(unix_timestamp) 
                    FROM system_metrics
                """)
                time_range = cursor.fetchone()
                
                # è³‡æ–™åº«æª”æ¡ˆå¤§å°
                db_size = self.db_path.stat().st_size if self.db_path.exists() else 0
                
                stats = {
                    'total_records': total_records,
                    'database_size_mb': round(db_size / (1024 * 1024), 2),
                    'earliest_record': None,
                    'latest_record': None
                }
                
                if time_range[0] and time_range[1]:
                    stats['earliest_record'] = datetime.fromtimestamp(time_range[0]).isoformat()
                    stats['latest_record'] = datetime.fromtimestamp(time_range[1]).isoformat()
                
                return stats
                
        except Exception as e:
            print(f"âŒ ç²å–çµ±è¨ˆå¤±æ•—: {e}")
            return {}
    
    def export_to_csv(self, output_path: str, 
                     start_time: Optional[datetime] = None,
                     end_time: Optional[datetime] = None) -> bool:
        """
        å°å‡ºæ•¸æ“šåˆ° CSV
        
        Args:
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
            start_time: é–‹å§‹æ™‚é–“
            end_time: çµæŸæ™‚é–“
            
        Returns:
            æ˜¯å¦å°å‡ºæˆåŠŸ
        """
        try:
            import csv
            
            metrics = self.get_metrics(start_time=start_time, end_time=end_time)
            
            if not metrics:
                print("âŒ æ²’æœ‰æ•¸æ“šå¯å°å‡º")
                return False
            
            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
                # å®šç¾©æ¬„ä½
                fieldnames = [
                    'timestamp', 'cpu_usage', 'ram_usage', 'ram_used_gb', 'ram_total_gb',
                    'gpu_usage', 'vram_usage', 'vram_used_mb', 'vram_total_mb', 'gpu_temperature'
                ]
                
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for metric in reversed(metrics):  # æ™‚é–“é †åº
                    row = {field: metric.get(field) for field in fieldnames}
                    writer.writerow(row)
            
            print(f"âœ… æˆåŠŸå°å‡º {len(metrics)} æ¢è¨˜éŒ„åˆ° {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ å°å‡º CSV å¤±æ•—: {e}")
            return False
    
    def set_config(self, key: str, value: str):
        """è¨­å®šé…ç½®é …ç›®"""
        try:
            with self._lock:
                with self._get_connection() as conn:
                    cursor = conn.cursor()
                    
                    cursor.execute("""
                        INSERT OR REPLACE INTO config (key, value, updated_at)
                        VALUES (?, ?, ?)
                    """, (key, value, datetime.now().isoformat()))
                    
                    conn.commit()
                    
        except Exception as e:
            print(f"âŒ è¨­å®šé…ç½®å¤±æ•—: {e}")
    
    def get_config(self, key: str, default: str = None) -> Optional[str]:
        """ç²å–é…ç½®é …ç›®"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                cursor.execute("SELECT value FROM config WHERE key = ?", (key,))
                result = cursor.fetchone()
                
                return result[0] if result else default
                
        except Exception as e:
            print(f"âŒ ç²å–é…ç½®å¤±æ•—: {e}")
            return default


def main():
    """æ¸¬è©¦å­˜å„²åŠŸèƒ½"""
    print("ğŸ—„ï¸  ç³»çµ±ç›£æ§æ•¸æ“šåº«æ¸¬è©¦")
    print("=" * 50)
    
    # å‰µå»ºæ¸¬è©¦æ•¸æ“šåº«
    db = MonitoringDatabase("test_monitoring.db")
    
    # æ’å…¥æ¸¬è©¦æ•¸æ“š
    print("ğŸ“ æ’å…¥æ¸¬è©¦æ•¸æ“š...")
    test_data = {
        'timestamp': datetime.now().isoformat(),
        'unix_timestamp': datetime.now().timestamp(),
        'cpu_usage': 45.5,
        'ram_usage': 67.2,
        'ram_used_gb': 8.5,
        'ram_total_gb': 16.0,
        'gpu_usage': 85.3,
        'vram_usage': 75.0,
        'vram_used_mb': 6000,
        'vram_total_mb': 8000,
        'gpu_temperature': 72
    }
    
    success = db.insert_metrics(test_data)
    print(f"æ’å…¥çµæœ: {'æˆåŠŸ' if success else 'å¤±æ•—'}")
    
    # æŸ¥è©¢æ•¸æ“š
    print("\nğŸ“Š æŸ¥è©¢æœ€æ–°æ•¸æ“š...")
    latest = db.get_latest_metrics(count=1)
    if latest:
        metric = latest[0]
        print(f"æ™‚é–“: {metric['timestamp']}")
        print(f"CPU: {metric['cpu_usage']}%")
        print(f"RAM: {metric['ram_usage']}%")
        if metric['gpu_usage']:
            print(f"GPU: {metric['gpu_usage']}%")
    
    # çµ±è¨ˆè³‡è¨Š
    print("\nğŸ“ˆ è³‡æ–™åº«çµ±è¨ˆ:")
    stats = db.get_statistics()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # å°å‡ºæ¸¬è©¦
    print("\nğŸ’¾ æ¸¬è©¦ CSV å°å‡º...")
    export_success = db.export_to_csv("test_export.csv")
    if export_success and Path("test_export.csv").exists():
        print("CSV å°å‡ºæˆåŠŸ")
        Path("test_export.csv").unlink()  # æ¸…ç†æ¸¬è©¦æª”æ¡ˆ
    
    # æ¸…ç†æ¸¬è©¦è³‡æ–™åº«
    if Path("test_monitoring.db").exists():
        Path("test_monitoring.db").unlink()
    
    print("\nâœ… æ•¸æ“šåº«æ¸¬è©¦å®Œæˆ")


if __name__ == "__main__":
    main()