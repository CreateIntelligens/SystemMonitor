#!/usr/bin/env python3
"""
ç³»çµ±è³‡æºæ”¶é›†å™¨
æ”¶é›† GPUã€CPUã€RAM ä½¿ç”¨ç‡æ•¸æ“š
"""

import subprocess
import psutil
import re
import json
import time
import requests
from datetime import datetime
from typing import Dict, Optional, List
try:
    import docker
except ImportError:
    docker = None
try:
    import pynvml
    PYNVML_AVAILABLE = True
except ImportError:
    PYNVML_AVAILABLE = False
    pynvml = None


class GPUCollector:
    """NVIDIA GPU æ•¸æ“šæ”¶é›†å™¨"""
    
    def __init__(self):
        self.gpu_available = self._check_nvidia_smi()
        self.docker_client = self._init_docker_client()
        self.debug = True
        self.nvml_initialized = False
        self._init_nvml()
    
    def _init_docker_client(self):
        """åˆå§‹åŒ–Dockerå®¢æˆ¶ç«¯"""
        if docker is None:
            return None
        
        # å˜—è©¦å¤šç¨®é€£æ¥æ–¹å¼
        connection_attempts = [
            lambda: docker.from_env(),
            lambda: docker.DockerClient(base_url='unix://var/run/docker.sock'),
            lambda: docker.DockerClient(base_url='npipe:////./pipe/docker_engine'),  # Windows
            lambda: docker.DockerClient(base_url='tcp://host.docker.internal:2375'),
        ]
        
        for attempt in connection_attempts:
            try:
                client = attempt()
                # æ¸¬è©¦é€£æ¥
                client.ping()
                return client
            except Exception as e:
                continue
        return None
    
    def _init_nvml(self):
        """åˆå§‹åŒ– NVML"""
        if not PYNVML_AVAILABLE:
            return
        
        try:
            pynvml.nvmlInit()
            self.nvml_initialized = True
        except Exception as e:
            pass
    
    def get_pid_gpu_info(self, target_pid: int) -> Optional[Dict]:
        """ä½¿ç”¨ NVML æŸ¥è©¢ç‰¹å®š PID çš„ GPU ä½¿ç”¨æƒ…æ³ï¼ŒåŒ…å« VRAM å’Œ GPU ä½¿ç”¨ç‡"""
        if not self.nvml_initialized:
            return None
        
        try:
            device_count = pynvml.nvmlDeviceGetCount()
            
            for gpu_id in range(device_count):
                handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)
                
                # æª¢æŸ¥æœƒè¨ˆæ¨¡å¼æ˜¯å¦å•Ÿç”¨
                try:
                    accounting_enabled = (pynvml.nvmlDeviceGetAccountingMode(handle) == pynvml.NVML_FEATURE_ENABLED)
                except pynvml.NVMLError:
                    accounting_enabled = False

                # æŸ¥è©¢è¨ˆç®—å’Œåœ–å½¢é€²ç¨‹
                all_procs = []
                try:
                    all_procs.extend(pynvml.nvmlDeviceGetComputeRunningProcesses(handle))
                except pynvml.NVMLError:
                    pass
                try:
                    all_procs.extend(pynvml.nvmlDeviceGetGraphicsRunningProcesses(handle))
                except pynvml.NVMLError:
                    pass
                
                # æª¢æŸ¥ç›®æ¨™ PID
                for proc in all_procs:
                    if proc.pid == target_pid:
                        vram_used_mb = proc.usedGpuMemory // (1024 * 1024) if proc.usedGpuMemory is not None else 0
                        
                        # ç²å– GPU ä½¿ç”¨ç‡ (å¦‚æœæœƒè¨ˆæ¨¡å¼å•Ÿç”¨)
                        gpu_utilization = 0
                        if accounting_enabled:
                            try:
                                acc_stats = pynvml.nvmlDeviceGetAccountingStats(handle, target_pid)
                                if acc_stats.isRunning:
                                    gpu_utilization = acc_stats.gpuUtilization
                            except pynvml.NVMLError:
                                pass  # å¿½ç•¥éŒ¯èª¤ï¼Œå¯èƒ½åªæ˜¯è©²é€²ç¨‹æ²’æœ‰çµ±è¨ˆæ•¸æ“š

                        # ç²å– GPU åç¨±
                        try:
                            gpu_name = pynvml.nvmlDeviceGetName(handle).decode('utf-8')
                        except:
                            gpu_name = f"GPU {gpu_id}"
                        
                        return {
                            'gpu_id': gpu_id,
                            'gpu_name': gpu_name,
                            'vram_used_mb': vram_used_mb,
                            'gpu_utilization': gpu_utilization,
                            'found': True,
                            'detected_by_nvml': True
                        }
            
            return {'found': False}
            
        except Exception as e:
            if self.debug:
                pass
            return None
    
    def _build_pid_namespace_map(self) -> Dict[int, int]:
        """å»ºç«‹ PID æ˜ å°„è¡¨ï¼Œæ”¯æ´é›™å‘æŸ¥æ‰¾"""
        container_to_host = {}  # å®¹å™¨PID -> ä¸»æ©ŸPID
        host_to_container = {}  # ä¸»æ©ŸPID -> å®¹å™¨PID
        
        try:
            # æ–¹æ³•1: è®€å– /proc/*/status çš„ NSpid
            import os
            proc_path = "/host/proc" if os.path.exists("/host/proc") else "/proc"
            
            # æƒææ‰€æœ‰ä¸»æ©Ÿé€²ç¨‹
            if os.path.exists("/host/proc"):
                # åœ¨å®¹å™¨ä¸­ï¼Œæƒæä¸»æ©Ÿçš„ /proc
                for pid_dir in os.listdir("/host/proc"):
                    if not pid_dir.isdigit():
                        continue
                    
                    try:
                        host_pid = int(pid_dir)
                        status_file = f"/host/proc/{host_pid}/status"
                        
                        if os.path.exists(status_file):
                            with open(status_file, 'r') as f:
                                for line in f:
                                    if line.startswith('NSpid:'):
                                        pids = line.split(':')[1].strip().split()
                                        if len(pids) >= 2:
                                            # pids[0] æ˜¯ä¸»æ©ŸPIDï¼Œpids[1] æ˜¯å®¹å™¨PID
                                            actual_host_pid = int(pids[0])
                                            container_pid = int(pids[1])
                                            
                                            container_to_host[container_pid] = actual_host_pid
                                            host_to_container[actual_host_pid] = container_pid
                                            
                                            if self.debug:
                                                print(f"[DEBUG] PIDæ˜ å°„: å®¹å™¨{container_pid} -> ä¸»æ©Ÿ{actual_host_pid}")
                                        break
                    except (FileNotFoundError, PermissionError, ValueError, OSError):
                        continue
            else:
                # åœ¨ä¸»æ©Ÿä¸Šï¼Œä½¿ç”¨ psutil
                for proc in psutil.process_iter(['pid']):
                    try:
                        host_pid = proc.info['pid']
                        status_file = f"/proc/{host_pid}/status"
                        
                        if os.path.exists(status_file):
                            with open(status_file, 'r') as f:
                                for line in f:
                                    if line.startswith('NSpid:'):
                                        pids = line.split(':')[1].strip().split()
                                        if len(pids) >= 2:
                                            # pids[0] æ˜¯ä¸»æ©ŸPIDï¼Œpids[1] æ˜¯å®¹å™¨PID
                                            actual_host_pid = int(pids[0])
                                            container_pid = int(pids[1])
                                            
                                            container_to_host[container_pid] = actual_host_pid
                                            host_to_container[actual_host_pid] = container_pid
                                            
                                            if self.debug:
                                                print(f"[DEBUG] PIDæ˜ å°„: å®¹å™¨{container_pid} -> ä¸»æ©Ÿ{actual_host_pid}")
                                        break
                    except (FileNotFoundError, PermissionError, ValueError, psutil.NoSuchProcess, psutil.AccessDenied):
                        continue
                        
            if self.debug:
                print(f"[DEBUG] å»ºç«‹äº† {len(container_to_host)} å€‹ PID æ˜ å°„")
                    
        except Exception as e:
            if self.debug:
                print(f"[WARNING] PID namespaceæ˜ å°„å¤±æ•—: {e}")
        
        self.host_to_container = host_to_container
        return container_to_host
    
    def _get_container_process_map(self) -> Dict[int, Dict]:
        """ç²å–å®¹å™¨é€²ç¨‹æ˜ å°„è¡¨ (PID -> å®¹å™¨ä¿¡æ¯)"""
        container_map = {}
        if not self.docker_client:
            return container_map
        
        try:
            containers = self.docker_client.containers.list()
            for container in containers:
                try:
                    # ç²å–å®¹å™¨å…§çš„é€²ç¨‹
                    processes = container.top()['Processes']
                    container_info = {
                        'name': container.name,
                        'image': container.image.tags[0] if container.image.tags else 'unknown',
                        'status': container.status
                    }
                    
                    # è§£æé€²ç¨‹ä¿¡æ¯
                    for process in processes:
                        if len(process) >= 2:
                            try:
                                pid = int(process[1])  # é€šå¸¸PIDåœ¨ç¬¬äºŒåˆ—
                                container_map[pid] = container_info
                            except (ValueError, IndexError):
                                continue
                                
                except Exception:
                    continue
                    
        except Exception:
            pass
            
        return container_map
    
    def _check_nvidia_smi(self) -> bool:
        """æª¢æŸ¥ nvidia-smi æ˜¯å¦å¯ç”¨ï¼Œæ”¯æ´å¤šç¨®æª¢æ¸¬æ–¹å¼ä»¥æé«˜å…¼å®¹æ€§"""
        # å˜—è©¦å¤šç¨®nvidia-smiå‘½ä»¤ä¾†æª¢æ¸¬å¯ç”¨æ€§
        test_commands = [
            ['nvidia-smi', '--version'],       # æœ€å¸¸ç”¨çš„ç‰ˆæœ¬æª¢æŸ¥
            ['nvidia-smi', '--list-gpus'],     # é©ç”¨æ–¼è¼ƒèˆŠé©…å‹•ç‰ˆæœ¬
            ['nvidia-smi', '-L'],              # ç°¡çŸ­çš„GPUåˆ—è¡¨å‘½ä»¤
            ['nvidia-smi', '--help'],          # åŸºæœ¬å¹«åŠ©å‘½ä»¤
            ['nvidia-smi']                     # åŸºæœ¬ç‹€æ…‹æŸ¥è©¢
        ]
        
        for cmd in test_commands:
            try:
                result = subprocess.run(cmd, 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    print(f"[DEBUG] NVIDIA GPU æª¢æ¸¬æˆåŠŸï¼Œä½¿ç”¨å‘½ä»¤: {' '.join(cmd)}")
                    return True
            except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):
                continue
                
        pass
        return False
    
    def get_gpu_stats(self) -> Optional[Dict]:
        """ç²å– GPU ä½¿ç”¨çµ±è¨ˆ"""
        if not self.gpu_available:
            return None
        
        try:
            # æŸ¥è©¢ GPU ä½¿ç”¨ç‡å’Œè¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
            cmd = [
                'nvidia-smi',
                '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu,name',
                '--format=csv,noheader,nounits'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            if result.returncode != 0:
                return None
            
            # è§£æè¼¸å‡º
            lines = result.stdout.strip().split('\n')
            gpu_stats = []
            
            for i, line in enumerate(lines):
                if not line.strip():
                    continue
                    
                parts = [part.strip() for part in line.split(',')]
                if len(parts) >= 5:
                    try:
                        gpu_usage = int(parts[0]) if parts[0] and parts[0] != 'N/A' and parts[0].strip() else 0
                        memory_used = int(parts[1]) if parts[1] and parts[1] != 'N/A' and parts[1].strip() else 0
                        memory_total = int(parts[2]) if parts[2] and parts[2] != 'N/A' and parts[2].strip() else 1
                        temperature = int(parts[3]) if parts[3] and parts[3] != 'N/A' and parts[3].strip() else 0
                        gpu_name = parts[4] if len(parts) > 4 else 'Unknown GPU'
                        
                        vram_usage = (memory_used / memory_total * 100) if memory_total > 0 else 0
                        
                        gpu_stats.append({
                            'gpu_id': i,
                            'gpu_name': gpu_name,
                            'gpu_usage': gpu_usage,
                            'vram_used_mb': memory_used,
                            'vram_total_mb': memory_total,
                            'vram_usage': round(vram_usage, 2),
                            'temperature': temperature
                        })
                        
                    except (ValueError, ZeroDivisionError):
                        continue
            
            return gpu_stats if gpu_stats else None
            
        except (subprocess.TimeoutExpired, subprocess.SubprocessError):
            return None
    
    

    def get_gpu_processes(self) -> Optional[List[Dict]]:
        """ç²å– GPU é€²ç¨‹çš„æ··åˆæ–¹æ³•ã€‚
        1. ä¸»è¦æ–¹æ³•: è§£æ nvidia-smi çš„å®Œæ•´è¼¸å‡ºï¼Œç²å–è©³ç´°é€²ç¨‹ä¿¡æ¯ã€‚
        2. å‚™ç”¨æ–¹æ³•: æƒæç³»çµ±é€²ç¨‹åˆ—è¡¨ï¼ŒæŸ¥æ‰¾å¯èƒ½ä½¿ç”¨ GPU çš„é€²ç¨‹é—œéµå­—ã€‚
        3. æ–°å¢: æ•´åˆDockerå®¹å™¨ä¿¡æ¯ï¼Œè­˜åˆ¥é€²ç¨‹ä¾†æºã€‚
        """
        if not self.gpu_available:
            return None

        processes = {}
        
        # ç²å–å®¹å™¨é€²ç¨‹æ˜ å°„å’ŒPID namespaceæ˜ å°„
        container_map = self._get_container_process_map()
        pid_namespace_map = self._build_pid_namespace_map()  # å®¹å™¨PID -> ä¸»æ©ŸPID

        # 1. ä¸»è¦æ–¹æ³•: NVML (æ›´å¿«æ›´æº–ç¢º)
        if self.nvml_initialized:
            try:
                device_count = pynvml.nvmlDeviceGetCount()
                
                for gpu_id in range(device_count):
                    handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)

                    # æª¢æŸ¥æœƒè¨ˆæ¨¡å¼
                    try:
                        accounting_enabled = (pynvml.nvmlDeviceGetAccountingMode(handle) == pynvml.NVML_FEATURE_ENABLED)
                        if self.debug:
                            print(f"[DEBUG] GPU {gpu_id}: Accounting mode enabled: {accounting_enabled}")
                    except pynvml.NVMLError as e:
                        accounting_enabled = False
                        if self.debug:
                            print(f"[DEBUG] GPU {gpu_id}: Could not get accounting mode. Error: {e}")
                    
                    # ç²å–æ‰€æœ‰GPUé€²ç¨‹
                    all_procs = []
                    try:
                        compute_procs = pynvml.nvmlDeviceGetComputeRunningProcesses(handle)
                        all_procs.extend(compute_procs)
                        if self.debug:
                            print(f"[DEBUG] GPU {gpu_id}: æ‰¾åˆ° {len(compute_procs)} å€‹ Compute é€²ç¨‹")
                    except pynvml.NVMLError as e:
                        if self.debug:
                            print(f"[DEBUG] GPU {gpu_id}: ç„¡æ³•ç²å– Compute é€²ç¨‹: {e}")
                    try:
                        graphics_procs = pynvml.nvmlDeviceGetGraphicsRunningProcesses(handle)
                        all_procs.extend(graphics_procs)
                        if self.debug:
                            print(f"[DEBUG] GPU {gpu_id}: æ‰¾åˆ° {len(graphics_procs)} å€‹ Graphics é€²ç¨‹")
                    except pynvml.NVMLError as e:
                        if self.debug:
                            print(f"[DEBUG] GPU {gpu_id}: ç„¡æ³•ç²å– Graphics é€²ç¨‹: {e}")
                    
                    if self.debug:
                        print(f"[DEBUG] GPU {gpu_id}: ç¸½å…±æ‰¾åˆ° {len(all_procs)} å€‹ GPU é€²ç¨‹")
                    
                    # ç²å–GPUåç¨±
                    try:
                        gpu_name = pynvml.nvmlDeviceGetName(handle).decode('utf-8')
                    except:
                        gpu_name = f"GPU {gpu_id}"
                    
                    # è™•ç†æ¯å€‹GPUé€²ç¨‹
                    for proc in all_procs:
                        nvml_pid = proc.pid
                        vram_used_mb = proc.usedGpuMemory // (1024 * 1024) if proc.usedGpuMemory is not None else 0
                        
                        if self.debug:
                            print(f"[DEBUG] è™•ç† GPU é€²ç¨‹: NVML_PID={nvml_pid}, VRAM={vram_used_mb}MB")
                            # æ·»åŠ é€²ç¨‹è©³ç´°ä¿¡æ¯
                            try:
                                proc_name = pynvml.nvmlSystemGetProcessName(nvml_pid)
                                print(f"[DEBUG]   - NVML é€²ç¨‹åç¨±: {proc_name}")
                            except Exception as e:
                                print(f"[DEBUG]   - ç„¡æ³•å¾ NVML ç²å–é€²ç¨‹åç¨±: {e}")
                            
                            # é¡¯ç¤ºç•¶å‰çš„PIDæ˜ å°„ç‹€æ…‹
                            print(f"[DEBUG]   - å¯ç”¨çš„PIDæ˜ å°„: {dict(list(pid_namespace_map.items())[:5])}")  # åªé¡¯ç¤ºå‰5å€‹
                            print(f"[DEBUG]   - PID {nvml_pid} æ˜¯å¦å­˜åœ¨æ–¼ä¸»æ©Ÿ: {psutil.pid_exists(nvml_pid)}")
                            if nvml_pid in pid_namespace_map:
                                print(f"[DEBUG]   - å®¹å™¨PID {nvml_pid} -> ä¸»æ©ŸPID {pid_namespace_map[nvml_pid]}")
                        
                        # æ™ºèƒ½ PID è§£æï¼šNVML å¯èƒ½å›å ±ä¸»æ©Ÿ PID æˆ–å®¹å™¨ PID
                        target_pid = None
                        pid_source = "unknown"
                        
                        # æ–¹æ³•1: å‡è¨­ NVML å›å ±çš„æ˜¯ä¸»æ©Ÿ PIDï¼ˆæœ€å¸¸è¦‹æƒ…æ³ï¼‰
                        if psutil.pid_exists(nvml_pid):
                            target_pid = nvml_pid
                            pid_source = "direct_host"
                            if self.debug:
                                print(f"[DEBUG] NVML PID {nvml_pid} ç›´æ¥å­˜åœ¨æ–¼ä¸»æ©Ÿç³»çµ±ä¸­")
                        
                        # æ–¹æ³•2: å‡è¨­ NVML å›å ±çš„æ˜¯å®¹å™¨ PIDï¼Œéœ€è¦æ˜ å°„åˆ°ä¸»æ©Ÿ PID
                        elif nvml_pid in pid_namespace_map:
                            target_pid = pid_namespace_map[nvml_pid]
                            pid_source = "container_to_host"
                            if self.debug:
                                print(f"[DEBUG] å®¹å™¨PID {nvml_pid} æ˜ å°„åˆ°ä¸»æ©ŸPID {target_pid}")
                        
                        # æ–¹æ³•2b: æš«æ™‚ç¦ç”¨ Docker API æŸ¥æ‰¾ï¼ˆå› ç‚ºå­˜åœ¨å…¼å®¹æ€§å•é¡Œï¼‰
                        # elif self.docker_client:
                        #     # Docker API æŸ¥æ‰¾æš«æ™‚ç¦ç”¨
                        #     pass
                        
                        # æ–¹æ³•3: å˜—è©¦åå‘æŸ¥æ‰¾ - æª¢æŸ¥æ˜¯å¦æœ‰ä¸»æ©ŸPIDå°æ‡‰åˆ°é€™å€‹å®¹å™¨PID
                        else:
                            # åœ¨æ‰€æœ‰å·²çŸ¥çš„PIDæ˜ å°„ä¸­æŸ¥æ‰¾
                            found_host_pid = None
                            for container_pid, host_pid in pid_namespace_map.items():
                                # æª¢æŸ¥æ˜¯å¦æœ‰å…¶ä»–å®¹å™¨PIDæ˜ å°„åˆ°å¯èƒ½ç›¸é—œçš„ä¸»æ©ŸPID
                                if abs(container_pid - nvml_pid) <= 10:  # å®¹å™¨å…§PIDé€šå¸¸ç›¸è¿‘
                                    # é©—è­‰é€™å€‹ä¸»æ©ŸPIDæ˜¯å¦çœŸçš„åœ¨ä½¿ç”¨GPU
                                    verification = self.get_pid_gpu_info(host_pid)
                                    if verification and verification.get('found'):
                                        found_host_pid = host_pid
                                        if self.debug:
                                            print(f"[DEBUG] é€šéç›¸è¿‘PIDæ¨æ¸¬: å®¹å™¨PID {nvml_pid} å¯èƒ½å°æ‡‰ä¸»æ©ŸPID {host_pid}")
                                        break
                            
                            if found_host_pid:
                                target_pid = found_host_pid
                                pid_source = "nearby_pid_guess"
                            else:
                                # æ–¹æ³•4: æ™ºèƒ½æœç´¢ç­–ç•¥
                                if self.debug:
                                    print(f"[DEBUG] é–‹å§‹æ™ºèƒ½æœç´¢ä»¥æ‰¾åˆ° NVML PID {nvml_pid} çš„å°æ‡‰é€²ç¨‹")
                                
                                # ç­–ç•¥4a: æª¢æŸ¥æ‰€æœ‰å·²çŸ¥çš„ä¸»æ©ŸPIDï¼Œçœ‹æ˜¯å¦æœ‰ä½¿ç”¨GPUçš„
                                for host_pid in self.host_to_container.keys():
                                    try:
                                        verification = self.get_pid_gpu_info(host_pid)
                                        if verification and verification.get('found'):
                                            # æª¢æŸ¥VRAMä½¿ç”¨é‡æ˜¯å¦åŒ¹é…ï¼ˆå…è¨±å°å¹…å·®ç•°ï¼‰
                                            vram_diff = abs(verification.get('vram_used_mb', 0) - vram_used_mb)
                                            if vram_diff <= 1:  # å…è¨±1MBçš„å·®ç•°
                                                target_pid = host_pid
                                                pid_source = "host_pid_verification"
                                                if self.debug:
                                                    print(f"[DEBUG] é€šéä¸»æ©ŸPIDé©—è­‰æ‰¾åˆ°: NVML PID {nvml_pid} -> ä¸»æ©ŸPID {target_pid} (VRAMå·®ç•°: {vram_diff}MB)")
                                                break
                                    except:
                                        continue
                                
                                # ç­–ç•¥4b: å¦‚æœé‚„æ²’æ‰¾åˆ°ï¼Œæœç´¢å¯èƒ½çš„GPUé€²ç¨‹
                                if not target_pid and vram_used_mb > 0:  # åªæœ‰åœ¨æœ‰VRAMä½¿ç”¨æ™‚æ‰æœç´¢
                                    if self.debug:
                                        print(f"[DEBUG] é–‹å§‹æœç´¢VRAMä½¿ç”¨é‡ç‚º {vram_used_mb}MB çš„é€²ç¨‹")
                                    
                                    # é«˜æ•ˆæœç´¢ï¼šåªæª¢æŸ¥å¯èƒ½ä½¿ç”¨GPUçš„é€²ç¨‹é¡å‹
                                    search_count = 0
                                    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                                        search_count += 1
                                        if search_count > 100:  # é™åˆ¶æœç´¢æ•¸é‡
                                            break
                                            
                                        try:
                                            proc_name = proc.info['name'].lower()
                                            cmdline = ' '.join(proc.info.get('cmdline', [])).lower()
                                            
                                            # åªæª¢æŸ¥å¯èƒ½ä½¿ç”¨GPUçš„é€²ç¨‹
                                            gpu_keywords = ['python', 'torch', 'cuda', 'nvidia', 'tensorflow', 'uvr5', 'ncnn']
                                            if any(keyword in proc_name or keyword in cmdline for keyword in gpu_keywords):
                                                # ç›´æ¥ç”¨NVMLé©—è­‰
                                                verification = self.get_pid_gpu_info(proc.info['pid'])
                                                if verification and verification.get('found'):
                                                    vram_diff = abs(verification.get('vram_used_mb', 0) - vram_used_mb)
                                                    if vram_diff <= 2:  # å…è¨±2MBçš„å·®ç•°
                                                        target_pid = proc.info['pid']
                                                        pid_source = "keyword_search_match"
                                                        if self.debug:
                                                            print(f"[DEBUG] é—œéµå­—æœç´¢æ‰¾åˆ°åŒ¹é…: NVML PID {nvml_pid} -> ä¸»æ©ŸPID {target_pid} (VRAMå·®ç•°: {vram_diff}MB)")
                                                        break
                                        except (psutil.NoSuchProcess, psutil.AccessDenied):
                                            continue
                                    
                                    if self.debug:
                                        print(f"[DEBUG] é—œéµå­—æœç´¢æª¢æŸ¥äº† {search_count} å€‹é€²ç¨‹")
                        
                        # å°æ–¼Windows WDDMæ¨¡å¼ï¼Œç„¡æ³•ç²å¾—é€²ç¨‹ç´šåˆ¥çš„VRAMï¼Œä½†å¯ä»¥è¨˜éŒ„é€²ç¨‹å­˜åœ¨
                        if not target_pid:
                            if self.debug:
                                print(f"[DEBUG] ç„¡æ³•æ‰¾åˆ° NVML PID {nvml_pid} å°æ‡‰çš„ä¸»æ©ŸPID")
                                # åœ¨WDDMæ¨¡å¼ä¸‹ï¼Œå˜—è©¦è¨˜éŒ„Graphicsé€²ç¨‹è³‡è¨Š
                                try:
                                    proc_name = pynvml.nvmlSystemGetProcessName(nvml_pid)
                                    if proc_name and not proc_name.startswith('/X'):  # æ’é™¤X11ç›¸é—œé€²ç¨‹
                                        print(f"[DEBUG] Windows WDDMæ¨¡å¼ - ç™¼ç¾GPUé€²ç¨‹ä½†ç„¡æ³•æ˜ å°„PID: {proc_name}")
                                except:
                                    pass
                            continue

                        # ç²å– GPU ä½¿ç”¨ç‡
                        gpu_utilization = 0
                        if accounting_enabled:
                            try:
                                # ä½¿ç”¨ç›®æ¨™ PID é€²è¡ŒæŸ¥è©¢
                                acc_stats = pynvml.nvmlDeviceGetAccountingStats(handle, target_pid)
                                if acc_stats.isRunning:
                                    gpu_utilization = acc_stats.gpuUtilization
                                if self.debug:
                                    print(f"[DEBUG] PID {target_pid}: Accounting stats found. GPU Util: {gpu_utilization}")
                            except pynvml.NVMLError as e:
                                if self.debug:
                                    print(f"[DEBUG] PID {target_pid}: Could not get accounting stats. Error: {e}")
                                pass
                        elif self.debug:
                            print(f"[DEBUG] GPU {gpu_id}: Accounting mode disabled for PID {nvml_pid}. Skipping utilization check.")

                        if psutil.pid_exists(target_pid):
                            try:
                                p = psutil.Process(target_pid)
                                container_info = container_map.get(target_pid, None)
                                container_name = container_info['name'] if container_info else 'Host'
                                container_source = f"{container_info['name']} ({container_info['image']})" if container_info else 'ä¸»æ©Ÿ'
                                
                                # çµ„åˆé€²ç¨‹é¡å‹æè¿°
                                proc_type = f"ğŸ¯ GPU {gpu_id} ({gpu_name})"
                                if gpu_utilization > 0:
                                    proc_type += f" - {gpu_utilization}% GPU"
                                if vram_used_mb > 0:
                                    proc_type += f" - {vram_used_mb}MB VRAM"
                                if gpu_utilization == 0 and vram_used_mb == 0:
                                    proc_type += " - ä½¿ç”¨ä¸­"
                                
                                processes[target_pid] = {
                                    'pid': target_pid,
                                    'name': p.name(),
                                    'command': ' '.join(p.cmdline()) if p.cmdline() else 'Unknown',
                                    'gpu_memory_mb': vram_used_mb,
                                    'gpu_utilization': gpu_utilization,
                                    'cpu_percent': round(p.cpu_percent(), 1),
                                    'ram_mb': round(p.memory_info().rss / (1024 * 1024), 1),
                                    'start_time': datetime.fromtimestamp(p.create_time()).strftime('%m-%d %H:%M:%S'),
                                    'type': proc_type,
                                    'container': container_name,
                                    'container_source': container_source
                                }
                                
                                if self.debug:
                                    print(f"ğŸ¯ NVMLä¸»è¦æ–¹æ³•: PID {target_pid}(NVML:{nvml_pid},{pid_source}) ä½¿ç”¨ {proc_type}")
                                    
                            except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                                if self.debug:
                                    print(f"[DEBUG] ç„¡æ³•è¨ªå•PID {target_pid}: {e}")
                                continue
                        else:
                            if self.debug:
                                print(f"[DEBUG] PID {target_pid} ä¸å­˜åœ¨æ–¼ç³»çµ±ä¸­")
                                
            except Exception as e:
                if self.debug:
                    print(f"[WARNING] NVMLä¸»è¦æ–¹æ³•å¤±æ•—: {e}")
        
        # 2. å‚™ç”¨æ–¹æ³•: nvidia-smi (ç•¶NVMLå¤±æ•ˆæ™‚)
        if not self.nvml_initialized:
            if self.debug:
                print("[DEBUG] NVML æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨ nvidia-smi ä½œç‚ºå‚™ç”¨æ–¹æ¡ˆã€‚")
        elif not processes:  # åªæœ‰ç•¶NVMLæ²’æ‰¾åˆ°é€²ç¨‹æ™‚æ‰ç”¨nvidia-smi
            if self.debug:
                print("[DEBUG] NVML å·²åˆå§‹åŒ–ä½†æœªæ‰¾åˆ°é€²ç¨‹ï¼Œä½¿ç”¨ nvidia-smi ä½œç‚ºå‚™ç”¨æ–¹æ¡ˆã€‚")
                # åœ¨Windows WDDMæ¨¡å¼ä¸‹ï¼Œæä¾›ç¸½é«”GPUä½¿ç”¨æƒ…æ³
                try:
                    gpu_stats = self.get_gpu_stats()
                    if gpu_stats and len(gpu_stats) > 0:
                        gpu_info = gpu_stats[0]
                        if gpu_info.get('gpu_usage', 0) > 0 or gpu_info.get('vram_used_mb', 0) > 1000:
                            print(f"[DEBUG] Windows WDDMæ¨¡å¼ - GPUæ­£åœ¨ä½¿ç”¨ä¸­:")
                            print(f"[DEBUG]   - GPUä½¿ç”¨ç‡: {gpu_info.get('gpu_usage', 0)}%")
                            print(f"[DEBUG]   - VRAMä½¿ç”¨: {gpu_info.get('vram_used_mb', 0)}MB / {gpu_info.get('vram_total_mb', 0)}MB")
                            print(f"[DEBUG]   - æº«åº¦: {gpu_info.get('temperature', 0)}Â°C")
                except Exception as e:
                    print(f"[DEBUG] ç„¡æ³•ç²å–GPUç¸½é«”ç‹€æ…‹: {e}")
        
        if not self.nvml_initialized or not processes:
            try:
                # æ¨™æº–nvidia-smiè¼¸å‡º
                result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10, encoding='utf-8')
                if result.returncode == 0:
                    output = result.stdout
                    in_processes_section = False
                    for line in output.split('\n'):
                        if line.startswith('| Processes:'):
                            in_processes_section = True
                            continue
                        if not in_processes_section or not line.startswith('|'):
                            continue
                        
                        # è·³éåˆ†éš”ç·šå’Œæ¨™é¡Œè¡Œ
                        if '===' in line or 'GPU' in line or 'PID' in line or 'No running processes' in line:
                            continue
                        
                        # ç°¡å–®åˆ†å‰²è™•ç†ï¼Œæ›´ç©©å®š
                        line_cleaned = line.strip('|').strip()
                        if not line_cleaned:
                            continue
                            
                        # ä»¥ç©ºç™½åˆ†å‰²ï¼Œå°‹æ‰¾ PID å’Œè¨˜æ†¶é«”ä½¿ç”¨
                        parts = line_cleaned.split()
                        if len(parts) >= 5:
                            try:
                                # å…¸å‹æ ¼å¼: |   PID   Type   Process name                    GPU Memory Usage |
                                #          |     0    N/A    N/A        1234      C   python3                      123MiB |
                                
                                # æ‰¾åˆ°ç¬¬ä¸€å€‹æ•¸å­—ä½œç‚ºPID
                                pid = None
                                proc_type = None
                                memory_usage = None
                                
                                for i, part in enumerate(parts):
                                    if part.isdigit() and pid is None:
                                        pid = int(part)
                                    elif part in ['C', 'G', 'C+G'] and proc_type is None:
                                        proc_type = part
                                    elif part.endswith('MiB') and memory_usage is None:
                                        try:
                                            memory_usage = int(part.replace('MiB', ''))
                                        except ValueError:
                                            memory_usage = 0
                                
                                if pid is None:
                                    continue
                                    
                                proc_type = proc_type or 'Unknown'
                                gpu_memory_mb = memory_usage or 0
                                proc_name = ' '.join([p for p in parts if not p.isdigit() and p not in ['N/A', 'C', 'G', 'C+G'] and not p.endswith('MiB')])[:50]

                                if psutil.pid_exists(pid):
                                    p = psutil.Process(pid)
                                    
                                    # æª¢æŸ¥æ˜¯å¦ç‚ºå®¹å™¨é€²ç¨‹
                                    container_info = container_map.get(pid, None)
                                    container_name = container_info['name'] if container_info else 'Host'
                                    container_source = f"{container_info['name']} ({container_info['image']})" if container_info else 'ä¸»æ©Ÿ'
                                    
                                    processes[pid] = {
                                        'pid': pid, 
                                        'name': p.name(),
                                        'command': ' '.join(p.cmdline()) if p.cmdline() else proc_name,
                                        'gpu_memory_mb': gpu_memory_mb,
                                        'gpu_utilization': 0, # nvidia-smiä¸æä¾›æ­¤æ•¸æ“š
                                        'cpu_percent': round(p.cpu_percent(), 1),
                                        'ram_mb': round(p.memory_info().rss / (1024 * 1024), 1),
                                        'start_time': datetime.fromtimestamp(p.create_time()).strftime('%m-%d %H:%M:%S'),
                                        'type': f'NVIDIA {"Graphics" if proc_type == "G" else "Compute"}',
                                        'container': container_name,
                                        'container_source': container_source
                                    }
                            except (psutil.NoSuchProcess, psutil.AccessDenied, ValueError) as e:
                                if self.debug:
                                    print(f"âš ï¸  ç„¡æ³•è¨ªå•PID {pid}: {e}")
                                continue
                else:
                    if self.debug:
                        print(f"[WARNING] nvidia-smi å‘½ä»¤åŸ·è¡Œå¤±æ•—: {result.stderr}")

                # æ–¹æ³•2: å˜—è©¦compute appsæŸ¥è©¢è£œå……GPUè¨˜æ†¶é«”ä¿¡æ¯
                try:
                    compute_result = subprocess.run(['nvidia-smi', '--query-compute-apps=pid,used_memory', '--format=csv,noheader,nounits'], 
                                                  capture_output=True, text=True, timeout=10)
                    if compute_result.returncode == 0:
                        for line in compute_result.stdout.strip().split('\n'):
                            if line.strip():
                                parts = [p.strip() for p in line.split(',')]
                                if len(parts) >= 2:
                                    try:
                                        pid = int(parts[0]) if parts[0] and parts[0].isdigit() else None
                                        if pid is None:
                                            continue
                                        mem_usage = parts[1]
                                        gpu_memory_mb = int(mem_usage) if mem_usage and mem_usage != '[N/A]' and mem_usage.isdigit() else 0
                                        
                                        # æ›´æ–°å·²å­˜åœ¨çš„é€²ç¨‹æˆ–æ–°å¢é€²ç¨‹
                                        if pid in processes:
                                            processes[pid]['gpu_memory_mb'] = gpu_memory_mb
                                        elif psutil.pid_exists(pid):
                                            p = psutil.Process(pid)
                                            container_info = container_map.get(pid, None)
                                            container_name = container_info['name'] if container_info else 'Host'
                                            container_source = f"{container_info['name']} ({container_info['image']})" if container_info else 'ä¸»æ©Ÿ'
                                            
                                            processes[pid] = {
                                                'pid': pid,
                                                'name': p.name(),
                                                'command': ' '.join(p.cmdline()) if p.cmdline() else 'Unknown',
                                                'gpu_memory_mb': gpu_memory_mb,
                                                'gpu_utilization': 0, # nvidia-smiä¸æä¾›æ­¤æ•¸æ“š
                                                'cpu_percent': round(p.cpu_percent(), 1),
                                                'ram_mb': round(p.memory_info().rss / (1024 * 1024), 1),
                                                'start_time': datetime.fromtimestamp(p.create_time()).strftime('%m-%d %H:%M:%S'),
                                                'type': 'NVIDIA Compute',
                                                'container': container_name,
                                                'container_source': container_source
                                            }
                                    except (ValueError, psutil.NoSuchProcess, psutil.AccessDenied):
                                        continue
                except (subprocess.TimeoutExpired, subprocess.SubprocessError):
                    pass
            except (subprocess.TimeoutExpired, subprocess.SubprocessError, FileNotFoundError) as e:
                if self.debug:
                    print(f"[ERROR] åŸ·è¡Œ nvidia-smi æ™‚å‡ºéŒ¯: {e}")
        
        # 3. è£œå……æ–¹æ³•: é—œéµå­—æƒæ (æ‰¾å¯èƒ½éºæ¼çš„GPUç›¸é—œé€²ç¨‹)
        try:
            gpu_keywords = ['torch', 'cuda', 'tensorflow', 'uvr5', 'ncnn']
            for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'cpu_percent', 'memory_info', 'create_time']):
                if proc.info['pid'] in processes: # å¦‚æœä¸»è¦æ–¹æ³•å·²ç¶“æ‰¾åˆ°äº†ï¼Œå°±è·³é
                    continue
                
                cmd_line = ' '.join(proc.info['cmdline'] or [])
                proc_name = proc.info['name'] or ''
                full_search_text = f"{proc_name} {cmd_line}".lower()
                
                # æª¢æŸ¥GPUé—œéµå­—
                has_gpu_keywords = any(keyword in full_search_text for keyword in gpu_keywords)
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºPythoné€²ç¨‹ï¼ˆæª¢æŸ¥é€²ç¨‹åå’Œå‘½ä»¤è¡Œï¼‰
                is_python_process = (
                    'python' in proc_name.lower() or 
                    'python' in cmd_line.lower()
                )
                
                if has_gpu_keywords or is_python_process:
                    p = psutil.Process(proc.info['pid'])
                    
                    # ä½¿ç”¨ NVML æŸ¥è©¢ç²¾ç¢ºçš„ GPU ä½¿ç”¨æƒ…æ³
                    # é¦–å…ˆç›´æ¥ç”¨ä¸»æ©ŸPIDæŸ¥è©¢
                    nvml_info = self.get_pid_gpu_info(p.pid)
                    
                    # å¦‚æœç›´æ¥æŸ¥è©¢å¤±æ•—ï¼Œå˜—è©¦åå‘PIDæ˜ å°„ (ä¸»æ©ŸPIDå¯èƒ½å°æ‡‰å®¹å™¨PID)
                    if not nvml_info or not nvml_info.get('found'):
                        # æŸ¥æ‰¾æ˜¯å¦æœ‰å®¹å™¨PIDå°æ‡‰åˆ°é€™å€‹ä¸»æ©ŸPID
                        for container_pid, host_pid in pid_namespace_map.items():
                            if host_pid == p.pid:
                                nvml_info = self.get_pid_gpu_info(container_pid)
                                if nvml_info and nvml_info.get('found') and self.debug:
                                    print(f"[DEBUG] é€šéPIDæ˜ å°„æ‰¾åˆ°: ä¸»æ©ŸPID {p.pid} <-> å®¹å™¨PID {container_pid}")
                                break
                    
                    gpu_memory_mb = 0
                    gpu_utilization = 0
                    proc_type = 'Potential GPU (Keyword)' if has_gpu_keywords else 'Python Process'
                    
                    if nvml_info and nvml_info.get('found'):
                        gpu_memory_mb = nvml_info.get('vram_used_mb', 0)
                        gpu_utilization = nvml_info.get('gpu_utilization', 0)
                        
                        # æ›´æ–°é€²ç¨‹é¡å‹æè¿°
                        proc_type = f"ğŸ¯ GPU {nvml_info['gpu_id']}"
                        if gpu_utilization > 0:
                            proc_type += f" - {gpu_utilization}% GPU"
                        if gpu_memory_mb > 0:
                            proc_type += f" - {gpu_memory_mb}MB VRAM"
                        if gpu_utilization == 0 and gpu_memory_mb == 0:
                            proc_type += " - ä½¿ç”¨ä¸­"

                        if self.debug:
                            print(f"ğŸ¯ NVML ç¢ºèª PID={p.pid} ä½¿ç”¨ GPU {nvml_info['gpu_id']}, VRAM={gpu_memory_mb}MB, Util={gpu_utilization}%")
                    else:
                        # Windows WDDMæ¨¡å¼ä¸‹ï¼Œç„¡æ³•ç²å¾—é€²ç¨‹ç´šVRAMï¼Œä½†å¯ä»¥æ ¹æ“šé—œéµå­—æ¨æ¸¬
                        if has_gpu_keywords:
                            # æª¢æŸ¥GPUæ˜¯å¦æ­£åœ¨è¢«å¤§é‡ä½¿ç”¨
                            try:
                                gpu_stats = self.get_gpu_stats()
                                if gpu_stats and len(gpu_stats) > 0:
                                    gpu_info = gpu_stats[0]
                                    if gpu_info.get('gpu_usage', 0) > 80:  # GPUä½¿ç”¨ç‡>80%
                                        proc_type = f"ğŸ”¥ å¯èƒ½çš„GPUé€²ç¨‹ (ç³»çµ±GPU: {gpu_info.get('gpu_usage', 0)}%)"
                                        if self.debug:
                                            print(f"ğŸ”¥ Windows WDDMæ¨¡å¼ - é«˜GPUä½¿ç”¨ç‡æ™‚ç™¼ç¾é—œéµå­—é€²ç¨‹: PID={p.pid}, åç¨±={proc_name}")
                                    elif self.debug:
                                        print(f"ğŸ” é—œéµå­—åŒ¹é…ä½†GPUä½¿ç”¨ç‡ä½: PID={p.pid}, åç¨±={proc_name}")
                                elif self.debug:
                                    print(f"ğŸ” é—œéµå­—åŒ¹é…ä½†ç„¡æ³•ç²å–GPUç‹€æ…‹: PID={p.pid}, åç¨±={proc_name}")
                            except:
                                if self.debug:
                                    print(f"ğŸ” é—œéµå­—åŒ¹é…ä½†GPUç‹€æ…‹æŸ¥è©¢å¤±æ•—: PID={p.pid}, åç¨±={proc_name}")
                        elif self.debug and is_python_process:
                            print(f"ğŸ Pythoné€²ç¨‹: PID={p.pid}, åç¨±={proc_name}")
                    
                    # æª¢æŸ¥æ˜¯å¦ç‚ºå®¹å™¨é€²ç¨‹
                    container_info = container_map.get(p.pid, None)
                    container_name = container_info['name'] if container_info else 'Host'
                    container_source = f"{container_info['name']} ({container_info['image']})" if container_info else 'ä¸»æ©Ÿ'
                    
                    # é¿å…é‡è¤‡ï¼šå¦‚æœè©²é€²ç¨‹å·²ç¶“åœ¨ processes ä¸­ï¼Œæ›´æ–°å…¶è³‡è¨Šè€Œä¸æ˜¯è¦†è“‹
                    if p.pid not in processes:
                        processes[p.pid] = {
                            'pid': p.pid, 
                            'name': p.name(),
                            'command': cmd_line,
                            'gpu_memory_mb': gpu_memory_mb,
                            'gpu_utilization': gpu_utilization,
                            'cpu_percent': round(p.cpu_percent(), 1),
                            'ram_mb': round(p.memory_info().rss / (1024 * 1024), 1),
                            'start_time': datetime.fromtimestamp(p.create_time()).strftime('%m-%d %H:%M:%S'),
                            'type': proc_type,
                            'container': container_name,
                            'container_source': container_source
                        }
                    else:
                        # å¦‚æœé€²ç¨‹å·²å­˜åœ¨ï¼Œä½†æœ‰æ›´æº–ç¢ºçš„GPUè³‡è¨Šï¼Œå‰‡æ›´æ–°
                        existing = processes[p.pid]
                        if gpu_memory_mb > existing.get('gpu_memory_mb', 0):
                            existing['gpu_memory_mb'] = gpu_memory_mb
                            existing['gpu_utilization'] = gpu_utilization
                            existing['type'] = proc_type
                            if self.debug:
                                print(f"[DEBUG] æ›´æ–°ç¾æœ‰é€²ç¨‹ {p.pid} çš„GPUè³‡è¨Š: {gpu_memory_mb}MB")
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            pass

        return list(processes.values()) if processes else None
    
    
    
    def get_top_gpu_processes(self, limit: int = 10) -> Optional[List[Dict]]:
        """ç²å–ä½”ç”¨ GPU æœ€å¤šçš„é€²ç¨‹"""
        processes = self.get_gpu_processes()
        if not processes:
            return None
        
        # æŒ‰ GPU è¨˜æ†¶é«”ä½¿ç”¨é‡æ’åº
        sorted_processes = sorted(processes, key=lambda x: x['gpu_memory_mb'], reverse=True)
        return sorted_processes[:limit]


class WindowsHostCollector:
    """Windows ä¸»æ©Ÿè³‡æºæ”¶é›†å™¨ï¼ˆé€šé HTTP è«‹æ±‚ç²å–ï¼‰"""
    
    def __init__(self, host_url="http://host.docker.internal:9182"):
        self.host_url = host_url
        self.timeout = 5
    
    def _get_windows_metrics(self):
        """å¾ windows_exporter ç²å–æŒ‡æ¨™"""
        try:
            response = requests.get(f"{self.host_url}/metrics", timeout=self.timeout)
            if response.status_code == 200:
                return response.text
        except:
            pass
        return None
    
    def _parse_prometheus_metric(self, metrics_text, metric_name):
        """è§£æ Prometheus æ ¼å¼çš„æŒ‡æ¨™"""
        try:
            lines = metrics_text.split('\n')
            for line in lines:
                if line.startswith(metric_name) and not line.startswith('#'):
                    # æå–æ•¸å€¼
                    parts = line.split()
                    if len(parts) >= 2:
                        return float(parts[-1])
        except:
            pass
        return None
    
    def get_windows_cpu_usage(self):
        """ç²å– Windows CPU ä½¿ç”¨ç‡"""
        metrics = self._get_windows_metrics()
        if not metrics:
            return None
        
        # è§£æ CPU ä½¿ç”¨ç‡ï¼ˆ100 - idleï¼‰
        cpu_idle = self._parse_prometheus_metric(metrics, 'windows_cpu_time_total{mode="idle"}')
        if cpu_idle is not None:
            return round(100 - cpu_idle, 2)
        return None
    
    def get_windows_memory_stats(self):
        """ç²å– Windows è¨˜æ†¶é«”çµ±è¨ˆ"""
        metrics = self._get_windows_metrics()
        if not metrics:
            return None
        
        try:
            # è§£æè¨˜æ†¶é«”æŒ‡æ¨™
            total_memory = self._parse_prometheus_metric(metrics, 'windows_os_physical_memory_total_bytes')
            free_memory = self._parse_prometheus_metric(metrics, 'windows_os_physical_memory_free_bytes')
            
            if total_memory and free_memory:
                used_memory = total_memory - free_memory
                usage_percent = (used_memory / total_memory) * 100
                
                return {
                    'ram_total_gb': round(total_memory / (1024**3), 2),
                    'ram_used_gb': round(used_memory / (1024**3), 2),
                    'ram_usage': round(usage_percent, 2),
                    'ram_available_gb': round(free_memory / (1024**3), 2),
                    'source': 'windows_host'
                }
        except:
            pass
        return None


class SystemCollector:
    """ç³»çµ± CPU å’Œè¨˜æ†¶é«”æ”¶é›†å™¨"""
    
    def __init__(self):
        self.windows_collector = WindowsHostCollector()
    
    def _read_host_cpu_stats(self):
        """è®€å–ä¸»æ©Ÿ CPU çµ±è¨ˆ"""
        import os
        if not os.path.exists('/host/proc/stat'):
            return None
        
        try:
            with open('/host/proc/stat', 'r') as f:
                line = f.readline()
                if line.startswith('cpu '):
                    values = [int(x) for x in line.split()[1:]]
                    # values: [user, nice, system, idle, iowait, irq, softirq, steal, guest, guest_nice]
                    idle = values[3]
                    total = sum(values)
                    return {'idle': idle, 'total': total}
        except:
            pass
        return None
    
    def _get_host_cpu_usage(self):
        """è¨ˆç®—ä¸»æ©Ÿ CPU ä½¿ç”¨ç‡"""
        try:
            # è®€å–å…©æ¬¡ CPU çµ±è¨ˆä¾†è¨ˆç®—ä½¿ç”¨ç‡
            stat1 = self._read_host_cpu_stats()
            if not stat1:
                return None
            
            time.sleep(1)  # ç­‰å¾… 1 ç§’
            
            stat2 = self._read_host_cpu_stats()
            if not stat2:
                return None
            
            # è¨ˆç®—å·®å€¼
            idle_diff = stat2['idle'] - stat1['idle']
            total_diff = stat2['total'] - stat1['total']
            
            if total_diff <= 0:
                return None
            
            # è¨ˆç®— CPU ä½¿ç”¨ç‡
            cpu_usage = (total_diff - idle_diff) / total_diff * 100
            return round(cpu_usage, 2)
            
        except Exception:
            return None
    
    def get_cpu_stats(self) -> Dict:
        """ç²å– CPU ä½¿ç”¨çµ±è¨ˆ"""
        try:
            # å˜—è©¦å¤šç¨®æ–¹æ³•ç²å– CPU ä½¿ç”¨ç‡
            cpu_percent = None
            source = 'unknown'
            
            # æ–¹æ³• 1: å˜—è©¦å¾ Windows Performance Counters ç²å–
            windows_cpu = self.windows_collector.get_windows_cpu_usage()
            if windows_cpu is not None:
                cpu_percent = windows_cpu
                source = 'windows_host'
            
            # æ–¹æ³• 2: å˜—è©¦å¾ä¸»æ©Ÿ /proc/stat ç²å–
            elif True:  # ç¸½æ˜¯å˜—è©¦é€™å€‹æ–¹æ³•ä½œç‚ºå‚™æ´
                host_cpu_usage = self._get_host_cpu_usage()
                if host_cpu_usage is not None:
                    cpu_percent = host_cpu_usage
                    source = 'host_proc'
                else:
                    # æ–¹æ³• 3: å›é€€åˆ°å®¹å™¨ CPU
                    cpu_percent = psutil.cpu_percent(interval=1)
                    source = 'container'
            
            cpu_count = psutil.cpu_count()
            cpu_freq = psutil.cpu_freq()
            
            # æ¯æ ¸å¿ƒä½¿ç”¨ç‡ï¼ˆåªèƒ½å¾å®¹å™¨ç²å–ï¼‰
            cpu_per_core = psutil.cpu_percent(percpu=True, interval=0.1)
            
            load_avg = None
            try:
                import os
                # å˜—è©¦å¾ä¸»æ©Ÿç²å– load average
                if os.path.exists('/host/proc/loadavg'):
                    with open('/host/proc/loadavg', 'r') as f:
                        line = f.readline().strip()
                        load_values = line.split()[:3]
                        load_avg = [float(x) for x in load_values]
                else:
                    # Linux/macOS å¯ç”¨
                    load_avg = psutil.getloadavg()
            except (AttributeError, FileNotFoundError, ValueError):
                # Windows ä¸æ”¯æ´ load average
                pass
            
            return {
                'cpu_usage': round(cpu_percent, 2) if cpu_percent is not None else 0,
                'cpu_count': cpu_count,
                'cpu_freq_mhz': round(cpu_freq.current) if cpu_freq else None,
                'cpu_per_core': [round(usage, 2) for usage in cpu_per_core],
                'load_avg': [round(load, 2) for load in load_avg] if load_avg else None,
                'source': source
            }
            
        except Exception as e:
            return {
                'cpu_usage': 0,
                'cpu_count': psutil.cpu_count(),
                'error': str(e),
                'source': 'error'
            }
    
    def get_memory_stats(self) -> Dict:
        """ç²å–è¨˜æ†¶é«”ä½¿ç”¨çµ±è¨ˆ"""
        try:
            # ç³»çµ±è¨˜æ†¶é«”
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()
            
            # å˜—è©¦å¾ /proc/meminfo ç²å–æ›´æº–ç¢ºçš„ä¸»æ©Ÿè¨˜æ†¶é«”ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯åœ¨å®¹å™¨ä¸­ï¼‰
            host_memory_info = None
            try:
                import os
                if os.path.exists('/host/proc/meminfo'):
                    # è®€å–ä¸»æ©Ÿçš„è¨˜æ†¶é«”ä¿¡æ¯
                    with open('/host/proc/meminfo', 'r') as f:
                        meminfo = {}
                        for line in f:
                            parts = line.strip().split()
                            if len(parts) >= 2:
                                key = parts[0].rstrip(':')
                                value = int(parts[1]) * 1024  # KB to bytes
                                meminfo[key] = value
                    
                    if 'MemTotal' in meminfo and 'MemAvailable' in meminfo:
                        host_total = meminfo['MemTotal']
                        host_available = meminfo['MemAvailable']
                        host_used = host_total - host_available
                        host_percent = (host_used / host_total) * 100
                        
                        host_memory_info = {
                            'ram_total_gb': round(host_total / (1024**3), 2),
                            'ram_used_gb': round(host_used / (1024**3), 2),
                            'ram_usage': round(host_percent, 2),
                            'ram_available_gb': round(host_available / (1024**3), 2),
                            'source': 'host'
                        }
            except:
                pass
            
            # å¦‚æœæœ‰ä¸»æ©Ÿè¨˜æ†¶é«”ä¿¡æ¯ï¼Œä½¿ç”¨ä¸»æ©Ÿçš„ï¼Œå¦å‰‡ä½¿ç”¨å®¹å™¨çš„
            if host_memory_info:
                result = host_memory_info
                result.update({
                    'swap_total_gb': round(swap.total / (1024**3), 2),
                    'swap_used_gb': round(swap.used / (1024**3), 2),
                    'swap_usage': round(swap.percent, 2) if swap.total > 0 else 0
                })
                return result
            else:
                return {
                    'ram_total_gb': round(memory.total / (1024**3), 2),
                    'ram_used_gb': round(memory.used / (1024**3), 2),
                    'ram_usage': round(memory.percent, 2),
                    'ram_available_gb': round(memory.available / (1024**3), 2),
                    'swap_total_gb': round(swap.total / (1024**3), 2),
                    'swap_used_gb': round(swap.used / (1024**3), 2),
                    'swap_usage': round(swap.percent, 2) if swap.total > 0 else 0,
                    'source': 'container'
                }
            
        except Exception as e:
            return {
                'ram_usage': 0,
                'ram_total_gb': 0,
                'error': str(e)
            }


class SystemMonitorCollector:
    """çµ±åˆç³»çµ±ç›£æ§æ”¶é›†å™¨"""
    
    def __init__(self):
        self.gpu_collector = GPUCollector()
        self.system_collector = SystemCollector()
    
    def collect_all(self) -> Dict:
        """æ”¶é›†æ‰€æœ‰ç³»çµ±æ•¸æ“š"""
        timestamp = datetime.now()
        
        # æ”¶é›† GPU æ•¸æ“š
        gpu_data = self.gpu_collector.get_gpu_stats()
        
        # æ”¶é›† GPU é€²ç¨‹æ•¸æ“š
        gpu_processes = self.gpu_collector.get_gpu_processes()
        
        # æ”¶é›†ç³»çµ±æ•¸æ“š
        cpu_data = self.system_collector.get_cpu_stats()
        memory_data = self.system_collector.get_memory_stats()
        
        # çµ±åˆæ•¸æ“š
        data = {
            'timestamp': timestamp.isoformat(),
            'unix_timestamp': timestamp.timestamp(),
            'cpu': cpu_data,
            'memory': memory_data,
            'gpu': gpu_data,
            'gpu_processes': gpu_processes
        }
        
        return data
    
    def collect_simple(self) -> Dict:
        """æ”¶é›†ç°¡åŒ–æ•¸æ“šï¼ˆç”¨æ–¼å­˜å„²ï¼‰"""
        all_data = self.collect_all()
        
        # æå–é—œéµæŒ‡æ¨™
        simple_data = {
            'timestamp': all_data['timestamp'],
            'unix_timestamp': all_data['unix_timestamp'],
            'cpu_usage': all_data['cpu'].get('cpu_usage', 0),
            'ram_usage': all_data['memory'].get('ram_usage', 0),
            'ram_used_gb': all_data['memory'].get('ram_used_gb', 0),
            'ram_total_gb': all_data['memory'].get('ram_total_gb', 0),
            'cpu_source': all_data['cpu'].get('source', 'N/A'),
            'ram_source': all_data['memory'].get('source', 'N/A'),
        }
        
        # æ·»åŠ  GPU æ•¸æ“šï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if all_data['gpu'] and len(all_data['gpu']) > 0:
            # ä½¿ç”¨ç¬¬ä¸€å€‹ GPU çš„æ•¸æ“š
            gpu0 = all_data['gpu'][0]
            simple_data.update({
                'gpu_usage': gpu0.get('gpu_usage', 0),
                'vram_usage': gpu0.get('vram_usage', 0),
                'vram_used_mb': gpu0.get('vram_used_mb', 0),
                'vram_total_mb': gpu0.get('vram_total_mb', 0),
                'gpu_temperature': gpu0.get('temperature', 0),
            })
        else:
            simple_data.update({
                'gpu_usage': None,
                'vram_usage': None,
                'vram_used_mb': None,
                'vram_total_mb': None,
                'gpu_temperature': None,
            })
        
        return simple_data
    
    def is_gpu_available(self) -> bool:
        """æª¢æŸ¥ GPU æ˜¯å¦å¯ç”¨"""
        return self.gpu_collector.gpu_available
    
    def get_top_gpu_processes(self, limit: int = 10) -> Optional[List[Dict]]:
        """ç²å–ä½”ç”¨ GPU æœ€å¤šçš„é€²ç¨‹"""
        return self.gpu_collector.get_top_gpu_processes(limit)


def main():
    """æ¸¬è©¦æ”¶é›†å™¨åŠŸèƒ½"""
    collector = SystemMonitorCollector()
    
    print("ğŸ” ç³»çµ±ç›£æ§æ”¶é›†å™¨æ¸¬è©¦")
    print("=" * 50)
    
    # æª¢æŸ¥ GPU å¯ç”¨æ€§
    if collector.is_gpu_available():
        print("âœ… NVIDIA GPU å¯ç”¨")
    else:
        print("âš ï¸  NVIDIA GPU ä¸å¯ç”¨ï¼Œå°‡åªç›£æ§ CPU/RAM")
    
    print("\nğŸ“Š æ”¶é›†ç³»çµ±æ•¸æ“š...")
    
    # æ”¶é›†æ•¸æ“š
    data = collector.collect_all()
    
    print(f"â° æ™‚é–“: {data['timestamp']}")
    print(f"ğŸ–¥ï¸  CPU ä½¿ç”¨ç‡: {data['cpu']['cpu_usage']:.2f}%")
    print(f"ğŸ’¾ RAM ä½¿ç”¨ç‡: {data['memory']['ram_usage']:.2f}% ({data['memory']['ram_used_gb']:.2f}GB/{data['memory']['ram_total_gb']:.2f}GB)")
    
    if data['gpu']:
        for i, gpu in enumerate(data['gpu']):
            print(f"ğŸ® GPU {i} ({gpu['gpu_name']}): {gpu['gpu_usage']:.2f}%")
            print(f"ğŸ“ˆ VRAM {i}: {gpu['vram_usage']:.2f}% ({gpu['vram_used_mb']:.0f}MB/{gpu['vram_total_mb']:.0f}MB)")
            print(f"ğŸŒ¡ï¸  æº«åº¦ {i}: {gpu['temperature']}Â°C")
    
    print("\nğŸ“‹ ç°¡åŒ–æ•¸æ“šæ ¼å¼:")
    simple_data = collector.collect_simple()
    for key, value in simple_data.items():
        if value is not None:
            print(f"  {key}: {value}")


if __name__ == "__main__":
    main()
